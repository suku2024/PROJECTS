{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "(X_train,y_train),(X_test,y_test) = keras.datasets.mnist.load_data()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [   layers.Flatten(input_shape=(28,28)),\n",
    "        layers.Dense(20, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(15, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(10, activation=\"softmax\",name=\"layer3\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1/5\n",
       "\n",
       "\u001b[1m   1/1500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0201\n",
       "\u001b[1m  37/1500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9808 - loss: 0.0577  \n",
       "\u001b[1m  89/1500\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9809 - loss: 0.0596\n",
       "\u001b[1m 149/1500\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9803 - loss: 0.0617\n",
       "\u001b[1m 208/1500\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 973us/step - accuracy: 0.9801 - loss: 0.0628\n",
       "\u001b[1m 260/1500\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 975us/step - accuracy: 0.9798 - loss: 0.0641\n",
       "\u001b[1m 314/1500\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 968us/step - accuracy: 0.9795 - loss: 0.0653\n",
       "\u001b[1m 357/1500\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 994us/step - accuracy: 0.9791 - loss: 0.0664\n",
       "\u001b[1m 397/1500\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9788 - loss: 0.0675  \n",
       "\u001b[1m 437/1500\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9786 - loss: 0.0683\n",
       "\u001b[1m 483/1500\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9785 - loss: 0.0688\n",
       "\u001b[1m 525/1500\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9784 - loss: 0.0692\n",
       "\u001b[1m 568/1500\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9783 - loss: 0.0696\n",
       "\u001b[1m 611/1500\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9782 - loss: 0.0700\n",
       "\u001b[1m 652/1500\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9781 - loss: 0.0704\n",
       "\u001b[1m 690/1500\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9780 - loss: 0.0707\n",
       "\u001b[1m 729/1500\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9780 - loss: 0.0710\n",
       "\u001b[1m 767/1500\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9779 - loss: 0.0713\n",
       "\u001b[1m 801/1500\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9778 - loss: 0.0715\n",
       "\u001b[1m 829/1500\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9778 - loss: 0.0717\n",
       "\u001b[1m 858/1500\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9777 - loss: 0.0719\n",
       "\u001b[1m 881/1500\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9777 - loss: 0.0720\n",
       "\u001b[1m 905/1500\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9776 - loss: 0.0721\n",
       "\u001b[1m 941/1500\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9776 - loss: 0.0722\n",
       "\u001b[1m 994/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9775 - loss: 0.0724\n",
       "\u001b[1m1048/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9774 - loss: 0.0726\n",
       "\u001b[1m1097/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9774 - loss: 0.0728\n",
       "\u001b[1m1170/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9773 - loss: 0.0730\n",
       "\u001b[1m1227/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9773 - loss: 0.0732\n",
       "\u001b[1m1284/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9772 - loss: 0.0733\n",
       "\u001b[1m1337/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9772 - loss: 0.0735\n",
       "\u001b[1m1391/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9771 - loss: 0.0736\n",
       "\u001b[1m1447/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9771 - loss: 0.0737\n",
       "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9771 - loss: 0.0738 - val_accuracy: 0.9527 - val_loss: 0.1722\n",
       "Epoch 2/5\n",
       "\n",
       "\u001b[1m   1/1500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0300\n",
       "\u001b[1m  53/1500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 979us/step - accuracy: 0.9680 - loss: 0.0678\n",
       "\u001b[1m 111/1500\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 0.9715 - loss: 0.0680\n",
       "\u001b[1m 170/1500\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 0.9732 - loss: 0.0675\n",
       "\u001b[1m 231/1500\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.9740 - loss: 0.0678\n",
       "\u001b[1m 297/1500\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 0.9744 - loss: 0.0689\n",
       "\u001b[1m 358/1500\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.9744 - loss: 0.0704\n",
       "\u001b[1m 421/1500\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.9744 - loss: 0.0716\n",
       "\u001b[1m 480/1500\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9744 - loss: 0.0724\n",
       "\u001b[1m 533/1500\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.9744 - loss: 0.0728\n",
       "\u001b[1m 594/1500\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9746 - loss: 0.0730\n",
       "\u001b[1m 657/1500\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9747 - loss: 0.0730\n",
       "\u001b[1m 718/1500\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9748 - loss: 0.0731\n",
       "\u001b[1m 782/1500\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9748 - loss: 0.0733\n",
       "\u001b[1m 841/1500\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9749 - loss: 0.0734\n",
       "\u001b[1m 900/1500\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9750 - loss: 0.0735\n",
       "\u001b[1m 949/1500\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.9750 - loss: 0.0736\n",
       "\u001b[1m 982/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.9750 - loss: 0.0737\n",
       "\u001b[1m1013/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.9750 - loss: 0.0737\n",
       "\u001b[1m1041/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.9751 - loss: 0.0738\n",
       "\u001b[1m1059/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.9751 - loss: 0.0738\n",
       "\u001b[1m1076/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.9751 - loss: 0.0738\n",
       "\u001b[1m1102/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9751 - loss: 0.0738  \n",
       "\u001b[1m1135/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9751 - loss: 0.0739\n",
       "\u001b[1m1171/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9751 - loss: 0.0739\n",
       "\u001b[1m1204/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9751 - loss: 0.0739\n",
       "\u001b[1m1241/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9751 - loss: 0.0740\n",
       "\u001b[1m1278/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9752 - loss: 0.0740\n",
       "\u001b[1m1310/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9752 - loss: 0.0740\n",
       "\u001b[1m1339/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9752 - loss: 0.0741\n",
       "\u001b[1m1371/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9752 - loss: 0.0741\n",
       "\u001b[1m1401/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9752 - loss: 0.0741\n",
       "\u001b[1m1431/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9752 - loss: 0.0741\n",
       "\u001b[1m1462/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9752 - loss: 0.0741\n",
       "\u001b[1m1495/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9752 - loss: 0.0741\n",
       "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9752 - loss: 0.0741 - val_accuracy: 0.9555 - val_loss: 0.1667\n",
       "Epoch 3/5\n",
       "\n",
       "\u001b[1m   1/1500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0297\n",
       "\u001b[1m  34/1500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9790 - loss: 0.0684  \n",
       "\u001b[1m  70/1500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9784 - loss: 0.0670\n",
       "\u001b[1m 113/1500\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9783 - loss: 0.0672\n",
       "\u001b[1m 151/1500\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9780 - loss: 0.0681\n",
       "\u001b[1m 188/1500\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9779 - loss: 0.0684\n",
       "\u001b[1m 227/1500\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9778 - loss: 0.0685\n",
       "\u001b[1m 266/1500\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9777 - loss: 0.0684\n",
       "\u001b[1m 309/1500\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9777 - loss: 0.0682\n",
       "\u001b[1m 353/1500\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9777 - loss: 0.0682\n",
       "\u001b[1m 402/1500\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9776 - loss: 0.0681\n",
       "\u001b[1m 454/1500\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9776 - loss: 0.0682\n",
       "\u001b[1m 510/1500\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9774 - loss: 0.0683\n",
       "\u001b[1m 568/1500\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9774 - loss: 0.0686\n",
       "\u001b[1m 624/1500\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9773 - loss: 0.0688\n",
       "\u001b[1m 684/1500\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9774 - loss: 0.0689\n",
       "\u001b[1m 741/1500\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9774 - loss: 0.0689\n",
       "\u001b[1m 799/1500\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9774 - loss: 0.0690\n",
       "\u001b[1m 858/1500\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9775 - loss: 0.0690\n",
       "\u001b[1m 907/1500\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9775 - loss: 0.0691\n",
       "\u001b[1m 960/1500\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9775 - loss: 0.0691\n",
       "\u001b[1m1024/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9775 - loss: 0.0692\n",
       "\u001b[1m1088/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9775 - loss: 0.0693\n",
       "\u001b[1m1156/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9775 - loss: 0.0694\n",
       "\u001b[1m1218/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.9775 - loss: 0.0695\n",
       "\u001b[1m1273/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.9775 - loss: 0.0696\n",
       "\u001b[1m1331/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.9774 - loss: 0.0697\n",
       "\u001b[1m1384/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.9774 - loss: 0.0698\n",
       "\u001b[1m1440/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.9774 - loss: 0.0699\n",
       "\u001b[1m1499/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.9774 - loss: 0.0700\n",
       "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9774 - loss: 0.0700 - val_accuracy: 0.9607 - val_loss: 0.1531\n",
       "Epoch 4/5\n",
       "\n",
       "\u001b[1m   1/1500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0022\n",
       "\u001b[1m  63/1500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 0.9828 - loss: 0.0468\n",
       "\u001b[1m 116/1500\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 0.9833 - loss: 0.0476\n",
       "\u001b[1m 169/1500\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 0.9834 - loss: 0.0500\n",
       "\u001b[1m 231/1500\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.9831 - loss: 0.0533\n",
       "\u001b[1m 288/1500\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 0.9827 - loss: 0.0555\n",
       "\u001b[1m 340/1500\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 0.9824 - loss: 0.0568\n",
       "\u001b[1m 395/1500\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.9822 - loss: 0.0577\n",
       "\u001b[1m 461/1500\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9819 - loss: 0.0589\n",
       "\u001b[1m 519/1500\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.9816 - loss: 0.0598\n",
       "\u001b[1m 579/1500\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.9814 - loss: 0.0606\n",
       "\u001b[1m 634/1500\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.9812 - loss: 0.0611\n",
       "\u001b[1m 692/1500\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.9812 - loss: 0.0614\n",
       "\u001b[1m 749/1500\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.9811 - loss: 0.0617\n",
       "\u001b[1m 804/1500\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.9810 - loss: 0.0619\n",
       "\u001b[1m 861/1500\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.9809 - loss: 0.0621\n",
       "\u001b[1m 920/1500\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9808 - loss: 0.0623\n",
       "\u001b[1m 980/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.9807 - loss: 0.0624\n",
       "\u001b[1m1039/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.9806 - loss: 0.0627\n",
       "\u001b[1m1092/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9806 - loss: 0.0629\n",
       "\u001b[1m1146/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.9805 - loss: 0.0631\n",
       "\u001b[1m1205/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9804 - loss: 0.0633\n",
       "\u001b[1m1258/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.9803 - loss: 0.0635\n",
       "\u001b[1m1312/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.9802 - loss: 0.0637\n",
       "\u001b[1m1366/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9802 - loss: 0.0639\n",
       "\u001b[1m1419/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.9801 - loss: 0.0641\n",
       "\u001b[1m1471/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.9800 - loss: 0.0643\n",
       "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9800 - loss: 0.0644 - val_accuracy: 0.9571 - val_loss: 0.1552\n",
       "Epoch 5/5\n",
       "\n",
       "\u001b[1m   1/1500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0188\n",
       "\u001b[1m  54/1500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 958us/step - accuracy: 0.9869 - loss: 0.0506\n",
       "\u001b[1m 116/1500\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.9863 - loss: 0.0524\n",
       "\u001b[1m 171/1500\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 0.9858 - loss: 0.0529\n",
       "\u001b[1m 234/1500\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.9855 - loss: 0.0529\n",
       "\u001b[1m 296/1500\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 0.9850 - loss: 0.0531\n",
       "\u001b[1m 359/1500\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9846 - loss: 0.0536\n",
       "\u001b[1m 423/1500\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9843 - loss: 0.0541\n",
       "\u001b[1m 478/1500\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9840 - loss: 0.0544\n",
       "\u001b[1m 531/1500\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.9838 - loss: 0.0548\n",
       "\u001b[1m 595/1500\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9835 - loss: 0.0552\n",
       "\u001b[1m 656/1500\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9832 - loss: 0.0560\n",
       "\u001b[1m 712/1500\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9830 - loss: 0.0566\n",
       "\u001b[1m 766/1500\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.9828 - loss: 0.0571\n",
       "\u001b[1m 828/1500\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9826 - loss: 0.0577\n",
       "\u001b[1m 888/1500\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.9824 - loss: 0.0583\n",
       "\u001b[1m 952/1500\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9822 - loss: 0.0589\n",
       "\u001b[1m1015/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9820 - loss: 0.0594\n",
       "\u001b[1m1073/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9818 - loss: 0.0598\n",
       "\u001b[1m1133/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9817 - loss: 0.0602\n",
       "\u001b[1m1191/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9815 - loss: 0.0606\n",
       "\u001b[1m1241/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.9814 - loss: 0.0609\n",
       "\u001b[1m1286/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.9813 - loss: 0.0612\n",
       "\u001b[1m1315/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.9813 - loss: 0.0614\n",
       "\u001b[1m1350/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.9812 - loss: 0.0616\n",
       "\u001b[1m1379/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.9811 - loss: 0.0617\n",
       "\u001b[1m1414/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.9811 - loss: 0.0619\n",
       "\u001b[1m1447/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.9810 - loss: 0.0620\n",
       "\u001b[1m1478/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.9810 - loss: 0.0622\n",
       "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9809 - loss: 0.0623 - val_accuracy: 0.9587 - val_loss: 0.1539\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5, validation_split=0.2)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
       "\u001b[1m 80/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 646us/step\n",
       "\u001b[1m171/313\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 600us/step\n",
       "\u001b[1m246/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 620us/step\n",
       "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step\n",
       "[7 2 1 ... 4 5 6]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_prob = model.predict(X_test)\n",
    "y_pred = y_prob.argmax(axis=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9537\n",
       "[7 2 1 ... 4 5 6]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = accuracy_score(y_test,y_pred)\n",
    "print(acc)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D object at 0x000002DCBC9EDAF0>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
       "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
       "[7]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.predict(X_test[0].reshape(1,28,28)).argmax(axis=1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
